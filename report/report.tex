\documentclass[a4paper,11pt]{article}

\usepackage{physics}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{enumerate}
%you can add more packages using the same code above

%------------------

\setlength{\topmargin}{0.0in}
\setlength{\textheight}{10in}
\setlength{\oddsidemargin}{0.0in}
\setlength{\evensidemargin}{0.0in}
\setlength{\textwidth}{6.5in}

%-------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}


\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{example}{Example}

%------------------

%Everything before begin document is called the pre-amble and sets out how the document will look
%It is recommended you don't touch the pre-amble until you are familiar with LateX

\begin{document}
	
\title{Semester Project - Personalization}
\author{Diba Hashemi}
\date{}
\maketitle


\section{Definitions}
We consider the federated learning setting in which there are $N$ clients with individual loss functions $\{f_i\}_{i \in [N]}$ on local distribution $\{\mathcal{D}_i\}_{i \in [N]}$ (Which could be IID, or not), and the independent noise $\{\xi_i\}_{i \in [N]}$. 
For now, we are interested in the personalized scenario, i.e. minimizing each client's loss function separately. If clients have the same or similar tasks, collaboration might be helpful in order to converge faster and achieve better results. In federated learning, the problem is usually to optimize the average loss function 
$min_{x \in \mathcal{R}^d} f(x):= \frac 1 n \sum_{i} f_i(x)$; however, we are interested in the personalized case where the goal is to minimize each $f_i(x)$ locally. In this case, if clients have the same or similar tasks, collaboration can be helpful in order to converge faster and achieve better results.
\\ 
%TODO: add a definition of similar or same tasks (similarity of gradients)
We investigate the case that some fraction of clients are adversaries and can send arbitrary messages to other honest agents. The fraction of adversary agents and the stochastic gradients of each agent are denoted as $\delta$ and $g_i(x):= \grad F(x, \xi_i)$.



\begin{theorem}
If $\delta \geq 1/2$, then for each client $i$, any gradient aggregation rule which is based on the distance with the local gradient of client $i$, cannot give a speed-up in convergence. 
\end{theorem}

%TODO: The proof only gives an intuition and is not precise. I don't know how to make it more accurate
\begin{proof}
    We present an algorithm designed for adversary agents to ensure that the first client does not experience a speed-up. Setting $\delta$ to 1/2, we build a bijection between adversary and honest agents. Pick a pair of honest and adversary clients and denote the data they transmit to the initial client as $g_a$ and $g_h$, respectively. Also, let $g_f$ be the gradient of the first client. Then, $g_h$ is derived from $g_a$ by mirroring it with respect to $g_f$, i.e. $2g_f - g_h$.
    Consequently, as the distance between the $g_f$ and $g_a$, and $g_f$ and $g_h$ are the same, any gradient aggregation rule which is based on the distance, assigns equal weights to both $g_a$ and $g_h$. Summing all the pairs up, the result would be exactly equal to $g_f$ which means collaboration is not useful in this case.\\
    For the case that $\delta > 1/2$, the argument is almost the same. It would be sufficient for the remaining adversary agents to report an identical gradient as $g_f$.
\end{proof}

\end{document}